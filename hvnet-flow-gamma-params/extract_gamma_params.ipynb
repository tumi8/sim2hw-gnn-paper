{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23cbacdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pandas as pd\n",
    "from pandas.errors import EmptyDataError\n",
    "from scipy.stats import gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60d71e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "HVNET_LATENCY_DATA_DIR = '../latency-data/hvnet/'\n",
    "TOPO_CONFIG_DIR = '../network-configs'\n",
    "\n",
    "NUM_TOPOS = 100\n",
    "\n",
    "CLEAN_RUN = False\n",
    "\n",
    "MAX_SAMPLES_PER_RATE = 10000\n",
    "SEED = 1234\n",
    "\n",
    "IST_RATE_CSV = 'inter-send-times-rates.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b70dacf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topo 00: loading input data...processing flows...analysis...done.\n",
      "topo 01: loading input data...processing flows...analysis...done.\n",
      "topo 02: loading input data...processing flows...analysis...done.\n",
      "topo 03: loading input data...processing flows...analysis...done.\n",
      "topo 04: loading input data...processing flows...analysis...done.\n",
      "topo 05: loading input data...processing flows...analysis...done.\n",
      "topo 05: loading input data...processing flows...analysis...done.\n",
      "topo 06: loading input data...processing flows...analysis...done.\n",
      "topo 07: loading input data...processing flows...analysis...done.\n",
      "topo 08: loading input data...processing flows...analysis...done.\n",
      "topo 09: loading input data...processing flows...analysis...done.\n",
      "topo 10: loading input data...processing flows...analysis...done.\n",
      "topo 11: loading input data...processing flows...analysis...done.\n",
      "topo 12: loading input data...processing flows...analysis...done.\n",
      "topo 13: loading input data...processing flows...analysis...done.\n",
      "topo 14: loading input data...processing flows...analysis...done.\n",
      "topo 15: loading input data...processing flows...analysis...done.\n",
      "topo 16: loading input data...processing flows...analysis...done.\n",
      "topo 17: loading input data...processing flows...analysis...done.\n",
      "topo 18: loading input data...processing flows...analysis...done.\n",
      "topo 19: loading input data...processing flows...analysis...done.\n",
      "topo 20: loading input data...processing flows...analysis...done.\n",
      "topo 21: loading input data...processing flows...analysis...done.\n",
      "topo 22: loading input data...processing flows...analysis...done.\n",
      "topo 23: loading input data...processing flows...analysis...done.\n",
      "topo 24: loading input data...processing flows...analysis...done.\n",
      "topo 25: loading input data...processing flows...analysis...done.\n",
      "topo 26: loading input data...processing flows...analysis...done.\n",
      "topo 27: loading input data...processing flows...analysis...done.\n",
      "topo 28: loading input data...processing flows...analysis...done.\n",
      "topo 29: loading input data...processing flows...analysis...done.\n",
      "topo 30: loading input data...processing flows...analysis...done.\n",
      "topo 31: loading input data...processing flows...analysis...done.\n",
      "topo 32: loading input data...processing flows...analysis...done.\n",
      "topo 33: loading input data...empty, skipping.\n",
      "topo 34: loading input data...processing flows...analysis...done.\n",
      "topo 35: loading input data...processing flows...analysis...done.\n",
      "topo 36: loading input data...processing flows...analysis...done.\n",
      "topo 37: loading input data...processing flows...analysis...done.\n",
      "topo 38: loading input data...processing flows...analysis...done.\n",
      "topo 39: loading input data...processing flows...analysis...done.\n",
      "topo 40: loading input data...processing flows...analysis...done.\n",
      "topo 41: loading input data...processing flows...analysis...done.\n",
      "topo 42: loading input data...processing flows...analysis...done.\n",
      "topo 43: loading input data...processing flows...analysis...done.\n",
      "topo 44: loading input data...processing flows...analysis...done.\n",
      "topo 45: loading input data...processing flows...analysis...done.\n",
      "topo 46: loading input data...processing flows...analysis...done.\n",
      "topo 47: loading input data...processing flows...analysis...done.\n",
      "topo 48: loading input data...processing flows...analysis...done.\n",
      "topo 49: loading input data...processing flows...analysis...done.\n",
      "topo 50: loading input data...processing flows...analysis...done.\n",
      "topo 51: loading input data...processing flows...analysis...done.\n",
      "topo 52: loading input data...processing flows...analysis...done.\n",
      "topo 53: loading input data...processing flows...analysis...done.\n",
      "topo 54: loading input data...processing flows...analysis...done.\n",
      "topo 55: loading input data...processing flows...analysis...done.\n",
      "topo 56: loading input data...processing flows...analysis...done.\n",
      "topo 57: loading input data...processing flows...analysis...done.\n",
      "topo 58: loading input data...processing flows...analysis...done.\n",
      "topo 59: loading input data...processing flows...analysis...done.\n",
      "topo 60: loading input data...processing flows...analysis...done.\n",
      "topo 61: loading input data...processing flows...analysis...done.\n",
      "topo 62: loading input data...processing flows...analysis...done.\n",
      "topo 63: loading input data...processing flows...analysis...done.\n",
      "topo 64: loading input data...processing flows...analysis...done.\n",
      "topo 65: loading input data...processing flows...analysis...done.\n",
      "topo 66: loading input data...processing flows...analysis...done.\n",
      "topo 67: loading input data...processing flows...analysis...done.\n",
      "topo 68: loading input data...processing flows...analysis...done.\n",
      "topo 69: loading input data...processing flows...analysis...done.\n",
      "topo 70: loading input data...processing flows...analysis...done.\n",
      "topo 71: loading input data...processing flows...analysis...done.\n",
      "topo 72: loading input data...processing flows...analysis...done.\n",
      "topo 73: loading input data...processing flows...analysis...done.\n",
      "topo 74: loading input data...processing flows...analysis...done.\n",
      "topo 75: loading input data...processing flows...analysis...done.\n",
      "topo 76: loading input data...processing flows...analysis...done.\n",
      "topo 77: loading input data...processing flows...analysis...done.\n",
      "topo 78: loading input data...empty, skipping.\n",
      "topo 79: loading input data...empty, skipping.\n",
      "topo 80: loading input data...processing flows...analysis...done.\n",
      "topo 81: loading input data...processing flows...analysis...done.\n",
      "topo 82: loading input data...processing flows...analysis...done.\n",
      "topo 83: loading input data...processing flows...analysis...done.\n",
      "topo 84: loading input data...processing flows...analysis...done.\n",
      "topo 85: loading input data...processing flows...analysis...done.\n",
      "topo 86: loading input data...processing flows...analysis...done.\n",
      "topo 87: loading input data...processing flows...analysis...done.\n",
      "topo 88: loading input data...processing flows...analysis...done.\n",
      "topo 89: loading input data...processing flows...analysis...done.\n",
      "topo 90: loading input data...processing flows...analysis...done.\n",
      "topo 91: loading input data...processing flows...analysis...done.\n",
      "topo 92: loading input data...processing flows...analysis...done.\n",
      "topo 93: loading input data...processing flows...analysis...done.\n",
      "topo 94: loading input data...processing flows...analysis...done.\n",
      "topo 95: loading input data...processing flows...analysis...done.\n",
      "topo 96: loading input data...processing flows...analysis...done.\n",
      "topo 97: loading input data...processing flows...analysis...done.\n",
      "topo 98: loading input data...processing flows...analysis...done.\n",
      "topo 99: loading input data...processing flows...analysis...done.\n"
     ]
    }
   ],
   "source": [
    "# Step 1 (per topology)\n",
    "# * load latency csv and config with rates per flow\n",
    "# * add flow column to latency df, drop unnecessary columns\n",
    "# * per flow, calculate inter-send times using send_time.diff()\n",
    "# * drop NaN values\n",
    "# * merge latency df with flow rates\n",
    "# * per rate, sample to x inter-send times\n",
    "# * export csv with the following columns: rate, inter_send_time\n",
    "\n",
    "def load_flow_config(i):\n",
    "    with open(os.path.join(TOPO_CONFIG_DIR, f'nw-{i}.json'), 'r') as f:\n",
    "        topo_config = json.load(f)\n",
    "    flow_config = topo_config['flow']\n",
    "    df = pd.DataFrame(flow_config)\n",
    "    df.rename(columns={'rate': 'rate_kbit_s'}, inplace=True)\n",
    "    df.rate_kbit_s = df.rate_kbit_s.astype('int')\n",
    "    return df\n",
    "\n",
    "def load_hvnet_latencies(i):\n",
    "    try:\n",
    "        df = pd.read_csv(os.path.join(HVNET_LATENCY_DATA_DIR, f'{i:02d}-latencies-hvnet-preprocessed.csv'))\n",
    "        df.drop(columns=['latency_us', 'recv_time_s'], inplace=True)\n",
    "    except FileNotFoundError:\n",
    "        return pd.DataFrame()\n",
    "    return df\n",
    "\n",
    "# Process all topologies\n",
    "df_list_ist_rate_all_topos = []\n",
    "for i in range(NUM_TOPOS):\n",
    "    IST_RATE_FILE_TOPO = f'inter-send-times-rates-{i:02d}.csv'\n",
    "    if not CLEAN_RUN and os.path.exists(IST_RATE_FILE_TOPO):\n",
    "        print(f'topo {i:02d} already processed, skipping.')\n",
    "        continue\n",
    "\n",
    "    print(f'topo {i:02d}: loading input data...', end='')\n",
    "\n",
    "    # Load flow data and HVNet latencies\n",
    "    df_flows = load_flow_config(i)\n",
    "    df_latency = load_hvnet_latencies(i)\n",
    "\n",
    "    if len(df_latency) == 0:\n",
    "        print('empty, skipping.')\n",
    "        continue\n",
    "\n",
    "    # Per flow, calculate inter-send times and export together with the flow rate\n",
    "    ist_series_per_flow = []\n",
    "    rates_per_flow = []\n",
    "    print('processing flows...', end='')\n",
    "    for f in df_latency.flow_num.unique():\n",
    "        flow_rate = df_flows[df_flows.name == f'f{f}'].iloc[0].rate_kbit_s * 1e3 / 8  # scale to byte per second\n",
    "\n",
    "        inter_send_times_f = df_latency[df_latency.flow_num == f].send_time_s.sort_values().diff().dropna()\n",
    "        ist_series_per_flow.append(inter_send_times_f)\n",
    "        rates_per_flow.extend([flow_rate] * len(inter_send_times_f))\n",
    "\n",
    "    print('analysis...', end='')\n",
    "    ist_series_all = pd.concat(ist_series_per_flow, ignore_index=True)\n",
    "    df_ist_rate = pd.DataFrame({\n",
    "        'inter_send_time_s': ist_series_all,\n",
    "        'rate_b_s': rates_per_flow\n",
    "    })\n",
    "\n",
    "    # Per rate, sample to MAX_SAMPLES_PER_RATE_PER_TOPO, save result to csv\n",
    "    df_ist_rate_sampled = df_ist_rate.groupby('rate_b_s').sample(n=MAX_SAMPLES_PER_RATE, random_state=SEED)\n",
    "    df_list_ist_rate_all_topos.append(df_ist_rate_sampled)\n",
    "    df_ist_rate_sampled.to_csv(f'inter-send-times-rates-{i:02d}.csv', index=False)\n",
    "    print('done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91e7881a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no data for topo 33, skipping.\n",
      "no data for topo 78, skipping.\n",
      "no data for topo 79, skipping.\n"
     ]
    }
   ],
   "source": [
    "# Combine all ist_rate dataframes, sample, and export as csv\n",
    "df_list_ist_rate_all_topos = []\n",
    "for i in range(NUM_TOPOS):\n",
    "    try:\n",
    "        df_list_ist_rate_all_topos.append(pd.read_csv(f'inter-send-times-rates-{i:02d}.csv'))\n",
    "    except (FileNotFoundError, EmptyDataError):\n",
    "        print(f'no data for topo {i:02d}, skipping.')\n",
    "        continue\n",
    "\n",
    "df_ist_rate_all_topos = pd.concat(df_list_ist_rate_all_topos, ignore_index=True, copy=False)\n",
    "df_ist_rate_all_topos = df_ist_rate_all_topos.groupby('rate_b_s').sample(n=MAX_SAMPLES_PER_RATE, random_state=SEED)\n",
    "df_ist_rate_all_topos.to_csv(IST_RATE_CSV, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67a99c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing rates...100%\n",
      "writing to file...done.\n"
     ]
    }
   ],
   "source": [
    "# Step 2\n",
    "# * load the previously generated csv\n",
    "# * per rate, call scipy.stats.gamma.fit()\n",
    "# * export tuples (shape, scale) for each rate\n",
    "# * write to csv\n",
    "\n",
    "df_ist_rate = pd.read_csv(IST_RATE_CSV)\n",
    "\n",
    "print('processing rates...', end='')\n",
    "rate_mapping = {}\n",
    "num_rates = len(df_ist_rate.rate_b_s.unique())\n",
    "for i, r in enumerate(df_ist_rate.rate_b_s.unique()):\n",
    "    print(f'\\rprocessing rates...{int((i/num_rates)*100):03d}%', end='')\n",
    "    ists_r = df_ist_rate[df_ist_rate.rate_b_s == r].inter_send_time_s\n",
    "    shape_r, _, scale_r = gamma.fit(ists_r, floc=0)  # fix the loc param to 0\n",
    "    rate_mapping[r] = {\n",
    "        'shape': shape_r,\n",
    "        'scale': scale_r\n",
    "    }\n",
    "print('\\rprocessing rates...100%')\n",
    "\n",
    "print('writing to file...', end='')\n",
    "with open('gamma-params.json', 'w') as f:\n",
    "    json.dump(rate_mapping, f)\n",
    "print('done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be90424a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3\n",
    "# * import mapping to OMNeT++ converter\n",
    "# * apply correct values according to flow rate"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
